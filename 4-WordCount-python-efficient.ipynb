{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop/MapReduce -- WordCount en Python (Implementación eficiente)\n",
    "===\n",
    "\n",
    "**Juan David Velásquez Henao**  \n",
    "jdvelasq@unal.edu.co   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia\n",
    "\n",
    "---\n",
    "\n",
    "Haga click [aquí](https://github.com/jdvelasq/big-data-analytics/tree/master/) para acceder al repositorio online.\n",
    "\n",
    "Haga click [aquí](http://nbviewer.jupyter.org/github/jdvelasq/big-data-analytics/tree/master/) para explorar el repositorio usando `nbviewer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición del problema\n",
    "\n",
    "Se desea contar la frecuencia de ocurrencia de palabras en un conjunto de documentos. Debido a los requerimientos de diseño (gran volúmen de datos y tiempos rápidos de respuesta) se desea implementar una arquitectura Big Data. Se desea implementar una **solución computacional eficiente** en **Python**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se generarán tres archivos de prueba para probar el sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se crea el directorio de entrada\n",
    "!rm -rf input output\n",
    "!mkdir input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text0.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text0.txt\n",
    "Analytics is the discovery, interpretation, and communication of meaningful patterns \n",
    "in data. Especially valuable in areas rich with recorded information, analytics relies \n",
    "on the simultaneous application of statistics, computer programming and operations research \n",
    "to quantify performance.\n",
    "\n",
    "Organizations may apply analytics to business data to describe, predict, and improve business \n",
    "performance. Specifically, areas within analytics include predictive analytics, prescriptive \n",
    "analytics, enterprise decision management, descriptive analytics, cognitive analytics, Big \n",
    "Data Analytics, retail analytics, store assortment and stock-keeping unit optimization, \n",
    "marketing optimization and marketing mix modeling, web analytics, call analytics, speech \n",
    "analytics, sales force sizing and optimization, price and promotion modeling, predictive \n",
    "science, credit risk analysis, and fraud analytics. Since analytics can require extensive \n",
    "computation (see big data), the algorithms and software used for analytics harness the most \n",
    "current methods in computer science, statistics, and mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text1.txt\n",
    "The field of data analysis. Analytics often involves studying past historical data to \n",
    "research potential trends, to analyze the effects of certain decisions or events, or to \n",
    "evaluate the performance of a given tool or scenario. The goal of analytics is to improve \n",
    "the business by gaining knowledge which can be used to make improvements or changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text2.txt\n",
    "Data analytics (DA) is the process of examining data sets in order to draw conclusions \n",
    "about the information they contain, increasingly with the aid of specialized systems \n",
    "and software. Data analytics technologies and techniques are widely used in commercial \n",
    "industries to enable organizations to make more-informed business decisions and by \n",
    "scientists and researchers to verify or disprove scientific models, theories and \n",
    "hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presenta una implementación eficiente en Python para el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1\n",
    "\n",
    "Implementación del `mapper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#! /usr/bin/env python\n",
    "\n",
    "##\n",
    "## Esta es la función que mapea la entrada a parejas (clave, valor)\n",
    "##\n",
    "import sys\n",
    "\n",
    "\n",
    "##\n",
    "## Se usa una clase iterable para implementar el mapper.\n",
    "##\n",
    "\n",
    "class Mapper:\n",
    "    \n",
    "    def __init__(self, stream):\n",
    "        ## \n",
    "        ## almacena el flujo de entrada como una\n",
    "        ## variable del objeto\n",
    "        ##\n",
    "        self.stream = stream\n",
    "    \n",
    "    def emit(self, key, value):\n",
    "        ##\n",
    "        ## escribe al flujo estándar de salida\n",
    "        ##\n",
    "        sys.stdout.write(\"{}\\t{}\\n\".format(key, value))\n",
    "        \n",
    "        \n",
    "    def status(self, message):\n",
    "        ##\n",
    "        ## imprime un reporte en el flujo de error\n",
    "        ## no se debe usar el stdout, ya que en este \n",
    "        ## unicamente deben ir las parejas (key, value)\n",
    "        ##\n",
    "        sys.stderr.write('reporter:status:{}\\n'.format(message))\n",
    "\n",
    "        \n",
    "    def counter(self, counter, amount=1, group=\"ApplicationCounter\"):\n",
    "        ## \n",
    "        ## imprime el valor del contador\n",
    "        ##\n",
    "        sys.stderr.write('reporter:counter:{},{},{}\\n'.format(group, counter, amount))\n",
    "        \n",
    "    def map(self):\n",
    "\n",
    "        word_counter = 0\n",
    "        \n",
    "        for word in self:\n",
    "            \n",
    "            ##\n",
    "            ## imprime un mensaje indicando la palabra procesada\n",
    "            ##\n",
    "            self.status('procesando ' + word)\n",
    "            \n",
    "            ##\n",
    "            ## cuenta la cantidad de palabras procesadas\n",
    "            ##\n",
    "            word_counter += 1\n",
    "            self.counter('num_words', amount=word_counter)\n",
    "\n",
    "            ##\n",
    "            ## por cada palabra del flujo de datos\n",
    "            ## emite la pareja (word, 1)\n",
    "            ##\n",
    "            self.emit(key=word, value=1)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        ##\n",
    "        ## itera sobre cada linea de código recibida\n",
    "        ## a través del flujo de entrada\n",
    "        ##\n",
    "        for line in self.stream:\n",
    "            ##\n",
    "            ## itera sobre cada palabra de la línea\n",
    "            ## (en los ciclos for, retorna las palabras\n",
    "            ## una a una)\n",
    "            ##\n",
    "            for word in line.split():\n",
    "                ##\n",
    "                ## retorna la palabra siguiente en el\n",
    "                ## ciclo for\n",
    "                ##\n",
    "                yield word\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    ##\n",
    "    ## inicializa el objeto con el flujo de entrada\n",
    "    ##\n",
    "    mapper = Mapper(sys.stdin)\n",
    "    \n",
    "    ##\n",
    "    ## ejecuta el mapper\n",
    "    ##\n",
    "    mapper.map()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## El programa anterior se hace ejecutable\n",
    "!chmod +x mapper.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reporter:status:procesando Analytics\n",
      "reporter:counter:ApplicationCounter,num_words,1\n",
      "reporter:status:procesando is\n",
      "reporter:counter:ApplicationCounter,num_words,2\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,3\n",
      "reporter:status:procesando discovery,\n",
      "reporter:counter:ApplicationCounter,num_words,4\n",
      "reporter:status:procesando interpretation,\n",
      "reporter:counter:ApplicationCounter,num_words,5\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,6\n",
      "reporter:status:procesando communication\n",
      "reporter:counter:ApplicationCounter,num_words,7\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,8\n",
      "reporter:status:procesando meaningful\n",
      "reporter:counter:ApplicationCounter,num_words,9\n",
      "reporter:status:procesando patterns\n",
      "reporter:counter:ApplicationCounter,num_words,10\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,11\n",
      "reporter:status:procesando data.\n",
      "reporter:counter:ApplicationCounter,num_words,12\n",
      "reporter:status:procesando Especially\n",
      "reporter:counter:ApplicationCounter,num_words,13\n",
      "reporter:status:procesando valuable\n",
      "reporter:counter:ApplicationCounter,num_words,14\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,15\n",
      "reporter:status:procesando areas\n",
      "reporter:counter:ApplicationCounter,num_words,16\n",
      "reporter:status:procesando rich\n",
      "reporter:counter:ApplicationCounter,num_words,17\n",
      "reporter:status:procesando with\n",
      "reporter:counter:ApplicationCounter,num_words,18\n",
      "reporter:status:procesando recorded\n",
      "reporter:counter:ApplicationCounter,num_words,19\n",
      "reporter:status:procesando information,\n",
      "reporter:counter:ApplicationCounter,num_words,20\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,21\n",
      "reporter:status:procesando relies\n",
      "reporter:counter:ApplicationCounter,num_words,22\n",
      "reporter:status:procesando on\n",
      "reporter:counter:ApplicationCounter,num_words,23\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,24\n",
      "reporter:status:procesando simultaneous\n",
      "reporter:counter:ApplicationCounter,num_words,25\n",
      "reporter:status:procesando application\n",
      "reporter:counter:ApplicationCounter,num_words,26\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,27\n",
      "reporter:status:procesando statistics,\n",
      "reporter:counter:ApplicationCounter,num_words,28\n",
      "reporter:status:procesando computer\n",
      "reporter:counter:ApplicationCounter,num_words,29\n",
      "reporter:status:procesando programming\n",
      "reporter:counter:ApplicationCounter,num_words,30\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,31\n",
      "reporter:status:procesando operations\n",
      "reporter:counter:ApplicationCounter,num_words,32\n",
      "reporter:status:procesando research\n",
      "reporter:counter:ApplicationCounter,num_words,33\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,34\n",
      "reporter:status:procesando quantify\n",
      "reporter:counter:ApplicationCounter,num_words,35\n",
      "reporter:status:procesando performance.\n",
      "reporter:counter:ApplicationCounter,num_words,36\n",
      "reporter:status:procesando Organizations\n",
      "reporter:counter:ApplicationCounter,num_words,37\n",
      "reporter:status:procesando may\n",
      "reporter:counter:ApplicationCounter,num_words,38\n",
      "reporter:status:procesando apply\n",
      "reporter:counter:ApplicationCounter,num_words,39\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,40\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,41\n",
      "reporter:status:procesando business\n",
      "reporter:counter:ApplicationCounter,num_words,42\n",
      "reporter:status:procesando data\n",
      "reporter:counter:ApplicationCounter,num_words,43\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,44\n",
      "reporter:status:procesando describe,\n",
      "reporter:counter:ApplicationCounter,num_words,45\n",
      "reporter:status:procesando predict,\n",
      "reporter:counter:ApplicationCounter,num_words,46\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,47\n",
      "reporter:status:procesando improve\n",
      "reporter:counter:ApplicationCounter,num_words,48\n",
      "reporter:status:procesando business\n",
      "reporter:counter:ApplicationCounter,num_words,49\n",
      "reporter:status:procesando performance.\n",
      "reporter:counter:ApplicationCounter,num_words,50\n",
      "reporter:status:procesando Specifically,\n",
      "reporter:counter:ApplicationCounter,num_words,51\n",
      "reporter:status:procesando areas\n",
      "reporter:counter:ApplicationCounter,num_words,52\n",
      "reporter:status:procesando within\n",
      "reporter:counter:ApplicationCounter,num_words,53\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,54\n",
      "reporter:status:procesando include\n",
      "reporter:counter:ApplicationCounter,num_words,55\n",
      "reporter:status:procesando predictive\n",
      "reporter:counter:ApplicationCounter,num_words,56\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,57\n",
      "reporter:status:procesando prescriptive\n",
      "reporter:counter:ApplicationCounter,num_words,58\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,59\n",
      "reporter:status:procesando enterprise\n",
      "reporter:counter:ApplicationCounter,num_words,60\n",
      "reporter:status:procesando decision\n",
      "reporter:counter:ApplicationCounter,num_words,61\n",
      "reporter:status:procesando management,\n",
      "reporter:counter:ApplicationCounter,num_words,62\n",
      "reporter:status:procesando descriptive\n",
      "reporter:counter:ApplicationCounter,num_words,63\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,64\n",
      "reporter:status:procesando cognitive\n",
      "reporter:counter:ApplicationCounter,num_words,65\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,66\n",
      "reporter:status:procesando Big\n",
      "reporter:counter:ApplicationCounter,num_words,67\n",
      "reporter:status:procesando Data\n",
      "reporter:counter:ApplicationCounter,num_words,68\n",
      "reporter:status:procesando Analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,69\n",
      "reporter:status:procesando retail\n",
      "reporter:counter:ApplicationCounter,num_words,70\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,71\n",
      "reporter:status:procesando store\n",
      "reporter:counter:ApplicationCounter,num_words,72\n",
      "reporter:status:procesando assortment\n",
      "reporter:counter:ApplicationCounter,num_words,73\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,74\n",
      "reporter:status:procesando stock-keeping\n",
      "reporter:counter:ApplicationCounter,num_words,75\n",
      "reporter:status:procesando unit\n",
      "reporter:counter:ApplicationCounter,num_words,76\n",
      "reporter:status:procesando optimization,\n",
      "reporter:counter:ApplicationCounter,num_words,77\n",
      "reporter:status:procesando marketing\n",
      "reporter:counter:ApplicationCounter,num_words,78\n",
      "reporter:status:procesando optimization\n",
      "reporter:counter:ApplicationCounter,num_words,79\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,80\n",
      "reporter:status:procesando marketing\n",
      "reporter:counter:ApplicationCounter,num_words,81\n",
      "reporter:status:procesando mix\n",
      "reporter:counter:ApplicationCounter,num_words,82\n",
      "reporter:status:procesando modeling,\n",
      "reporter:counter:ApplicationCounter,num_words,83\n",
      "reporter:status:procesando web\n",
      "reporter:counter:ApplicationCounter,num_words,84\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,85\n",
      "reporter:status:procesando call\n",
      "reporter:counter:ApplicationCounter,num_words,86\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,87\n",
      "reporter:status:procesando speech\n",
      "reporter:counter:ApplicationCounter,num_words,88\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,89\n",
      "reporter:status:procesando sales\n",
      "reporter:counter:ApplicationCounter,num_words,90\n",
      "reporter:status:procesando force\n",
      "reporter:counter:ApplicationCounter,num_words,91\n",
      "reporter:status:procesando sizing\n",
      "reporter:counter:ApplicationCounter,num_words,92\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,93\n",
      "reporter:status:procesando optimization,\n",
      "reporter:counter:ApplicationCounter,num_words,94\n",
      "reporter:status:procesando price\n",
      "reporter:counter:ApplicationCounter,num_words,95\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,96\n",
      "reporter:status:procesando promotion\n",
      "reporter:counter:ApplicationCounter,num_words,97\n",
      "reporter:status:procesando modeling,\n",
      "reporter:counter:ApplicationCounter,num_words,98\n",
      "reporter:status:procesando predictive\n",
      "reporter:counter:ApplicationCounter,num_words,99\n",
      "reporter:status:procesando science,\n",
      "reporter:counter:ApplicationCounter,num_words,100\n",
      "reporter:status:procesando credit\n",
      "reporter:counter:ApplicationCounter,num_words,101\n",
      "reporter:status:procesando risk\n",
      "reporter:counter:ApplicationCounter,num_words,102\n",
      "reporter:status:procesando analysis,\n",
      "reporter:counter:ApplicationCounter,num_words,103\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,104\n",
      "reporter:status:procesando fraud\n",
      "reporter:counter:ApplicationCounter,num_words,105\n",
      "reporter:status:procesando analytics.\n",
      "reporter:counter:ApplicationCounter,num_words,106\n",
      "reporter:status:procesando Since\n",
      "reporter:counter:ApplicationCounter,num_words,107\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,108\n",
      "reporter:status:procesando can\n",
      "reporter:counter:ApplicationCounter,num_words,109\n",
      "reporter:status:procesando require\n",
      "reporter:counter:ApplicationCounter,num_words,110\n",
      "reporter:status:procesando extensive\n",
      "reporter:counter:ApplicationCounter,num_words,111\n",
      "reporter:status:procesando computation\n",
      "reporter:counter:ApplicationCounter,num_words,112\n",
      "reporter:status:procesando (see\n",
      "reporter:counter:ApplicationCounter,num_words,113\n",
      "reporter:status:procesando big\n",
      "reporter:counter:ApplicationCounter,num_words,114\n",
      "reporter:status:procesando data),\n",
      "reporter:counter:ApplicationCounter,num_words,115\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,116\n",
      "reporter:status:procesando algorithms\n",
      "reporter:counter:ApplicationCounter,num_words,117\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,118\n",
      "reporter:status:procesando software\n",
      "reporter:counter:ApplicationCounter,num_words,119\n",
      "reporter:status:procesando used\n",
      "reporter:counter:ApplicationCounter,num_words,120\n",
      "reporter:status:procesando for\n",
      "reporter:counter:ApplicationCounter,num_words,121\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,122\n",
      "reporter:status:procesando harness\n",
      "reporter:counter:ApplicationCounter,num_words,123\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,124\n",
      "reporter:status:procesando most\n",
      "reporter:counter:ApplicationCounter,num_words,125\n",
      "reporter:status:procesando current\n",
      "reporter:counter:ApplicationCounter,num_words,126\n",
      "reporter:status:procesando methods\n",
      "reporter:counter:ApplicationCounter,num_words,127\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,128\n",
      "reporter:status:procesando computer\n",
      "reporter:counter:ApplicationCounter,num_words,129\n",
      "reporter:status:procesando science,\n",
      "reporter:counter:ApplicationCounter,num_words,130\n",
      "reporter:status:procesando statistics,\n",
      "reporter:counter:ApplicationCounter,num_words,131\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,132\n",
      "reporter:status:procesando mathematics.The\n",
      "reporter:counter:ApplicationCounter,num_words,133\n",
      "reporter:status:procesando field\n",
      "reporter:counter:ApplicationCounter,num_words,134\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,135\n",
      "reporter:status:procesando data\n",
      "reporter:counter:ApplicationCounter,num_words,136\n",
      "reporter:status:procesando analysis.\n",
      "reporter:counter:ApplicationCounter,num_words,137\n",
      "reporter:status:procesando Analytics\n",
      "reporter:counter:ApplicationCounter,num_words,138\n",
      "reporter:status:procesando often\n",
      "reporter:counter:ApplicationCounter,num_words,139\n",
      "reporter:status:procesando involves\n",
      "reporter:counter:ApplicationCounter,num_words,140\n",
      "reporter:status:procesando studying\n",
      "reporter:counter:ApplicationCounter,num_words,141\n",
      "reporter:status:procesando past\n",
      "reporter:counter:ApplicationCounter,num_words,142\n",
      "reporter:status:procesando historical\n",
      "reporter:counter:ApplicationCounter,num_words,143\n",
      "reporter:status:procesando data\n",
      "reporter:counter:ApplicationCounter,num_words,144\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,145\n",
      "reporter:status:procesando research\n",
      "reporter:counter:ApplicationCounter,num_words,146\n",
      "reporter:status:procesando potential\n",
      "reporter:counter:ApplicationCounter,num_words,147\n",
      "reporter:status:procesando trends,\n",
      "reporter:counter:ApplicationCounter,num_words,148\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,149\n",
      "reporter:status:procesando analyze\n",
      "reporter:counter:ApplicationCounter,num_words,150\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,151\n",
      "reporter:status:procesando effects\n",
      "reporter:counter:ApplicationCounter,num_words,152\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,153\n",
      "reporter:status:procesando certain\n",
      "reporter:counter:ApplicationCounter,num_words,154\n",
      "reporter:status:procesando decisions\n",
      "reporter:counter:ApplicationCounter,num_words,155\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,156\n",
      "reporter:status:procesando events,\n",
      "reporter:counter:ApplicationCounter,num_words,157\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,158\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,159\n",
      "reporter:status:procesando evaluate\n",
      "reporter:counter:ApplicationCounter,num_words,160\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,161\n",
      "reporter:status:procesando performance\n",
      "reporter:counter:ApplicationCounter,num_words,162\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,163\n",
      "reporter:status:procesando a\n",
      "reporter:counter:ApplicationCounter,num_words,164\n",
      "reporter:status:procesando given\n",
      "reporter:counter:ApplicationCounter,num_words,165\n",
      "reporter:status:procesando tool\n",
      "reporter:counter:ApplicationCounter,num_words,166\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,167\n",
      "reporter:status:procesando scenario.\n",
      "reporter:counter:ApplicationCounter,num_words,168\n",
      "reporter:status:procesando The\n",
      "reporter:counter:ApplicationCounter,num_words,169\n",
      "reporter:status:procesando goal\n",
      "reporter:counter:ApplicationCounter,num_words,170\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,171\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,172\n",
      "reporter:status:procesando is\n",
      "reporter:counter:ApplicationCounter,num_words,173\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,174\n",
      "reporter:status:procesando improve\n",
      "reporter:counter:ApplicationCounter,num_words,175\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,176\n",
      "reporter:status:procesando business\n",
      "reporter:counter:ApplicationCounter,num_words,177\n",
      "reporter:status:procesando by\n",
      "reporter:counter:ApplicationCounter,num_words,178\n",
      "reporter:status:procesando gaining\n",
      "reporter:counter:ApplicationCounter,num_words,179\n",
      "reporter:status:procesando knowledge\n",
      "reporter:counter:ApplicationCounter,num_words,180\n",
      "reporter:status:procesando which\n",
      "reporter:counter:ApplicationCounter,num_words,181\n",
      "reporter:status:procesando can\n",
      "reporter:counter:ApplicationCounter,num_words,182\n",
      "reporter:status:procesando be\n",
      "reporter:counter:ApplicationCounter,num_words,183\n",
      "reporter:status:procesando used\n",
      "reporter:counter:ApplicationCounter,num_words,184\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,185\n",
      "reporter:status:procesando make\n",
      "reporter:counter:ApplicationCounter,num_words,186\n",
      "reporter:status:procesando improvements\n",
      "reporter:counter:ApplicationCounter,num_words,187\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,188\n",
      "reporter:status:procesando changes.Data\n",
      "reporter:counter:ApplicationCounter,num_words,189\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,190\n",
      "reporter:status:procesando (DA)\n",
      "reporter:counter:ApplicationCounter,num_words,191\n",
      "reporter:status:procesando is\n",
      "reporter:counter:ApplicationCounter,num_words,192\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,193\n",
      "reporter:status:procesando process\n",
      "reporter:counter:ApplicationCounter,num_words,194\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,195\n",
      "reporter:status:procesando examining\n",
      "reporter:counter:ApplicationCounter,num_words,196\n",
      "reporter:status:procesando data\n",
      "reporter:counter:ApplicationCounter,num_words,197\n",
      "reporter:status:procesando sets\n",
      "reporter:counter:ApplicationCounter,num_words,198\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,199\n",
      "reporter:status:procesando order\n",
      "reporter:counter:ApplicationCounter,num_words,200\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,201\n",
      "reporter:status:procesando draw\n",
      "reporter:counter:ApplicationCounter,num_words,202\n",
      "reporter:status:procesando conclusions\n",
      "reporter:counter:ApplicationCounter,num_words,203\n",
      "reporter:status:procesando about\n",
      "reporter:counter:ApplicationCounter,num_words,204\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,205\n",
      "reporter:status:procesando information\n",
      "reporter:counter:ApplicationCounter,num_words,206\n",
      "reporter:status:procesando they\n",
      "reporter:counter:ApplicationCounter,num_words,207\n",
      "reporter:status:procesando contain,\n",
      "reporter:counter:ApplicationCounter,num_words,208\n",
      "reporter:status:procesando increasingly\n",
      "reporter:counter:ApplicationCounter,num_words,209\n",
      "reporter:status:procesando with\n",
      "reporter:counter:ApplicationCounter,num_words,210\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,211\n",
      "reporter:status:procesando aid\n",
      "reporter:counter:ApplicationCounter,num_words,212\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,213\n",
      "reporter:status:procesando specialized\n",
      "reporter:counter:ApplicationCounter,num_words,214\n",
      "reporter:status:procesando systems\n",
      "reporter:counter:ApplicationCounter,num_words,215\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,216\n",
      "reporter:status:procesando software.\n",
      "reporter:counter:ApplicationCounter,num_words,217\n",
      "reporter:status:procesando Data\n",
      "reporter:counter:ApplicationCounter,num_words,218\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,219\n",
      "reporter:status:procesando technologies\n",
      "reporter:counter:ApplicationCounter,num_words,220\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,221\n",
      "reporter:status:procesando techniques\n",
      "reporter:counter:ApplicationCounter,num_words,222\n",
      "reporter:status:procesando are\n",
      "reporter:counter:ApplicationCounter,num_words,223\n",
      "reporter:status:procesando widely\n",
      "reporter:counter:ApplicationCounter,num_words,224\n",
      "reporter:status:procesando used\n",
      "reporter:counter:ApplicationCounter,num_words,225\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,226\n",
      "reporter:status:procesando commercial\n",
      "reporter:counter:ApplicationCounter,num_words,227\n",
      "reporter:status:procesando industries\n",
      "reporter:counter:ApplicationCounter,num_words,228\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,229\n",
      "reporter:status:procesando enable\n",
      "reporter:counter:ApplicationCounter,num_words,230\n",
      "reporter:status:procesando organizations\n",
      "reporter:counter:ApplicationCounter,num_words,231\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,232\n",
      "reporter:status:procesando make\n",
      "reporter:counter:ApplicationCounter,num_words,233\n",
      "reporter:status:procesando more-informed\n",
      "reporter:counter:ApplicationCounter,num_words,234\n",
      "reporter:status:procesando business\n",
      "reporter:counter:ApplicationCounter,num_words,235\n",
      "reporter:status:procesando decisions\n",
      "reporter:counter:ApplicationCounter,num_words,236\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,237\n",
      "reporter:status:procesando by\n",
      "reporter:counter:ApplicationCounter,num_words,238\n",
      "reporter:status:procesando scientists\n",
      "reporter:counter:ApplicationCounter,num_words,239\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,240\n",
      "reporter:status:procesando researchers\n",
      "reporter:counter:ApplicationCounter,num_words,241\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,242\n",
      "reporter:status:procesando verify\n",
      "reporter:counter:ApplicationCounter,num_words,243\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,244\n",
      "reporter:status:procesando disprove\n",
      "reporter:counter:ApplicationCounter,num_words,245\n",
      "reporter:status:procesando scientific\n",
      "reporter:counter:ApplicationCounter,num_words,246\n",
      "reporter:status:procesando models,\n",
      "reporter:counter:ApplicationCounter,num_words,247\n",
      "reporter:status:procesando theories\n",
      "reporter:counter:ApplicationCounter,num_words,248\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,249\n",
      "reporter:status:procesando hypotheses.\n",
      "reporter:counter:ApplicationCounter,num_words,250\n",
      "Analytics\t1\n",
      "is\t1\n",
      "the\t1\n",
      "discovery,\t1\n",
      "interpretation,\t1\n",
      "and\t1\n",
      "communication\t1\n",
      "of\t1\n",
      "meaningful\t1\n",
      "patterns\t1\n"
     ]
    }
   ],
   "source": [
    "## la salida de la función anterior es:\n",
    "!cat ./input/text*.txt | ./mapper.py | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El reducer recibe las parejas (key, value) a través del flujo de salida. En los ejemplos anteriores, el reducer verifica si la clave cambia de un elemento al siguiente. Sin embargo, resulta más eficiente que se pueda iterar directamente sobre elementos consecutivos que tienen la misma clave. La función `groupby` de la librería `itertools` permite hacer esto. Dicha función recibe como argumentos los datos y una función que genera la clave para cada dato. Retorna una tupla con la clave y los elementos consecutivos que contienen la misma clave. El siguiente ejemplo permite clarificar su operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "    ('A', 1)\n",
      "B\n",
      "    ('B', 10)\n",
      "A\n",
      "    ('A', 2)\n",
      "    ('A', 3)\n",
      "    ('A', 4)\n",
      "B\n",
      "    ('B', 20)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "## la letra es la clave y los números son los valores\n",
    "data = [('A', 1), ('B', 10), ('A', 2), ('A', 3), ('A', 4) , ('B', 20)]\n",
    "\n",
    "## retorna la parte correspondiente a la clave\n",
    "def keyfun(x):\n",
    "    k, v = x\n",
    "    return k\n",
    "\n",
    "## itera sobre la clave y los elementos que contiene \n",
    "## la misma clave\n",
    "for key, group in itertools.groupby(data, keyfun):\n",
    "    print(key)\n",
    "    for g in group:\n",
    "        print('   ', g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se modifica el reducer para incoporar el uso de clases y de la función `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "class Reducer:\n",
    "    \n",
    "    def __init__(self, stream):\n",
    "        self.stream = stream\n",
    "        \n",
    "    def emit(self, key, value):\n",
    "        sys.stdout.write(\"{}\\t{}\\n\".format(key, value)) \n",
    "\n",
    "    def reduce(self):\n",
    "        ##\n",
    "        ## Esta función reduce los elementos que \n",
    "        ## tienen la misma clave\n",
    "        ##        \n",
    "        for key, group in itertools.groupby(self, lambda x: x[0]):\n",
    "            total = 0\n",
    "            for _, val in group:\n",
    "                total += val\n",
    "            \n",
    "            self.emit(key=key, value=total)\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        for line in self.stream:\n",
    "            ##\n",
    "            ## Lee el stream de datos y lo parte \n",
    "            ## en (clave, valor)\n",
    "            ##\n",
    "            key, val = line.split(\"\\t\") \n",
    "            val = int(val)\n",
    "            \n",
    "            ##\n",
    "            ## retorna la tupla (clave, valor)\n",
    "            ## como el siguiente elemento del ciclo for\n",
    "            ##\n",
    "            yield (key, val)\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "  \n",
    "    reducer = Reducer(sys.stdin)\n",
    "    reducer.reduce()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Se hace ejecutable el archivo\n",
    "!chmod +x reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5\n",
    "\n",
    "Se prueba la implementación localmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reporter:status:procesando Analytics\n",
      "reporter:counter:ApplicationCounter,num_words,1\n",
      "reporter:status:procesando is\n",
      "reporter:counter:ApplicationCounter,num_words,2\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,3\n",
      "reporter:status:procesando discovery,\n",
      "reporter:counter:ApplicationCounter,num_words,4\n",
      "reporter:status:procesando interpretation,\n",
      "reporter:counter:ApplicationCounter,num_words,5\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,6\n",
      "reporter:status:procesando communication\n",
      "reporter:counter:ApplicationCounter,num_words,7\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,8\n",
      "reporter:status:procesando meaningful\n",
      "reporter:counter:ApplicationCounter,num_words,9\n",
      "reporter:status:procesando patterns\n",
      "reporter:counter:ApplicationCounter,num_words,10\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,11\n",
      "reporter:status:procesando data.\n",
      "reporter:counter:ApplicationCounter,num_words,12\n",
      "reporter:status:procesando Especially\n",
      "reporter:counter:ApplicationCounter,num_words,13\n",
      "reporter:status:procesando valuable\n",
      "reporter:counter:ApplicationCounter,num_words,14\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,15\n",
      "reporter:status:procesando areas\n",
      "reporter:counter:ApplicationCounter,num_words,16\n",
      "reporter:status:procesando rich\n",
      "reporter:counter:ApplicationCounter,num_words,17\n",
      "reporter:status:procesando with\n",
      "reporter:counter:ApplicationCounter,num_words,18\n",
      "reporter:status:procesando recorded\n",
      "reporter:counter:ApplicationCounter,num_words,19\n",
      "reporter:status:procesando information,\n",
      "reporter:counter:ApplicationCounter,num_words,20\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,21\n",
      "reporter:status:procesando relies\n",
      "reporter:counter:ApplicationCounter,num_words,22\n",
      "reporter:status:procesando on\n",
      "reporter:counter:ApplicationCounter,num_words,23\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,24\n",
      "reporter:status:procesando simultaneous\n",
      "reporter:counter:ApplicationCounter,num_words,25\n",
      "reporter:status:procesando application\n",
      "reporter:counter:ApplicationCounter,num_words,26\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,27\n",
      "reporter:status:procesando statistics,\n",
      "reporter:counter:ApplicationCounter,num_words,28\n",
      "reporter:status:procesando computer\n",
      "reporter:counter:ApplicationCounter,num_words,29\n",
      "reporter:status:procesando programming\n",
      "reporter:counter:ApplicationCounter,num_words,30\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,31\n",
      "reporter:status:procesando operations\n",
      "reporter:counter:ApplicationCounter,num_words,32\n",
      "reporter:status:procesando research\n",
      "reporter:counter:ApplicationCounter,num_words,33\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,34\n",
      "reporter:status:procesando quantify\n",
      "reporter:counter:ApplicationCounter,num_words,35\n",
      "reporter:status:procesando performance.\n",
      "reporter:counter:ApplicationCounter,num_words,36\n",
      "reporter:status:procesando Organizations\n",
      "reporter:counter:ApplicationCounter,num_words,37\n",
      "reporter:status:procesando may\n",
      "reporter:counter:ApplicationCounter,num_words,38\n",
      "reporter:status:procesando apply\n",
      "reporter:counter:ApplicationCounter,num_words,39\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,40\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,41\n",
      "reporter:status:procesando business\n",
      "reporter:counter:ApplicationCounter,num_words,42\n",
      "reporter:status:procesando data\n",
      "reporter:counter:ApplicationCounter,num_words,43\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,44\n",
      "reporter:status:procesando describe,\n",
      "reporter:counter:ApplicationCounter,num_words,45\n",
      "reporter:status:procesando predict,\n",
      "reporter:counter:ApplicationCounter,num_words,46\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,47\n",
      "reporter:status:procesando improve\n",
      "reporter:counter:ApplicationCounter,num_words,48\n",
      "reporter:status:procesando business\n",
      "reporter:counter:ApplicationCounter,num_words,49\n",
      "reporter:status:procesando performance.\n",
      "reporter:counter:ApplicationCounter,num_words,50\n",
      "reporter:status:procesando Specifically,\n",
      "reporter:counter:ApplicationCounter,num_words,51\n",
      "reporter:status:procesando areas\n",
      "reporter:counter:ApplicationCounter,num_words,52\n",
      "reporter:status:procesando within\n",
      "reporter:counter:ApplicationCounter,num_words,53\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,54\n",
      "reporter:status:procesando include\n",
      "reporter:counter:ApplicationCounter,num_words,55\n",
      "reporter:status:procesando predictive\n",
      "reporter:counter:ApplicationCounter,num_words,56\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,57\n",
      "reporter:status:procesando prescriptive\n",
      "reporter:counter:ApplicationCounter,num_words,58\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,59\n",
      "reporter:status:procesando enterprise\n",
      "reporter:counter:ApplicationCounter,num_words,60\n",
      "reporter:status:procesando decision\n",
      "reporter:counter:ApplicationCounter,num_words,61\n",
      "reporter:status:procesando management,\n",
      "reporter:counter:ApplicationCounter,num_words,62\n",
      "reporter:status:procesando descriptive\n",
      "reporter:counter:ApplicationCounter,num_words,63\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,64\n",
      "reporter:status:procesando cognitive\n",
      "reporter:counter:ApplicationCounter,num_words,65\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,66\n",
      "reporter:status:procesando Big\n",
      "reporter:counter:ApplicationCounter,num_words,67\n",
      "reporter:status:procesando Data\n",
      "reporter:counter:ApplicationCounter,num_words,68\n",
      "reporter:status:procesando Analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,69\n",
      "reporter:status:procesando retail\n",
      "reporter:counter:ApplicationCounter,num_words,70\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,71\n",
      "reporter:status:procesando store\n",
      "reporter:counter:ApplicationCounter,num_words,72\n",
      "reporter:status:procesando assortment\n",
      "reporter:counter:ApplicationCounter,num_words,73\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,74\n",
      "reporter:status:procesando stock-keeping\n",
      "reporter:counter:ApplicationCounter,num_words,75\n",
      "reporter:status:procesando unit\n",
      "reporter:counter:ApplicationCounter,num_words,76\n",
      "reporter:status:procesando optimization,\n",
      "reporter:counter:ApplicationCounter,num_words,77\n",
      "reporter:status:procesando marketing\n",
      "reporter:counter:ApplicationCounter,num_words,78\n",
      "reporter:status:procesando optimization\n",
      "reporter:counter:ApplicationCounter,num_words,79\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,80\n",
      "reporter:status:procesando marketing\n",
      "reporter:counter:ApplicationCounter,num_words,81\n",
      "reporter:status:procesando mix\n",
      "reporter:counter:ApplicationCounter,num_words,82\n",
      "reporter:status:procesando modeling,\n",
      "reporter:counter:ApplicationCounter,num_words,83\n",
      "reporter:status:procesando web\n",
      "reporter:counter:ApplicationCounter,num_words,84\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,85\n",
      "reporter:status:procesando call\n",
      "reporter:counter:ApplicationCounter,num_words,86\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,87\n",
      "reporter:status:procesando speech\n",
      "reporter:counter:ApplicationCounter,num_words,88\n",
      "reporter:status:procesando analytics,\n",
      "reporter:counter:ApplicationCounter,num_words,89\n",
      "reporter:status:procesando sales\n",
      "reporter:counter:ApplicationCounter,num_words,90\n",
      "reporter:status:procesando force\n",
      "reporter:counter:ApplicationCounter,num_words,91\n",
      "reporter:status:procesando sizing\n",
      "reporter:counter:ApplicationCounter,num_words,92\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,93\n",
      "reporter:status:procesando optimization,\n",
      "reporter:counter:ApplicationCounter,num_words,94\n",
      "reporter:status:procesando price\n",
      "reporter:counter:ApplicationCounter,num_words,95\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,96\n",
      "reporter:status:procesando promotion\n",
      "reporter:counter:ApplicationCounter,num_words,97\n",
      "reporter:status:procesando modeling,\n",
      "reporter:counter:ApplicationCounter,num_words,98\n",
      "reporter:status:procesando predictive\n",
      "reporter:counter:ApplicationCounter,num_words,99\n",
      "reporter:status:procesando science,\n",
      "reporter:counter:ApplicationCounter,num_words,100\n",
      "reporter:status:procesando credit\n",
      "reporter:counter:ApplicationCounter,num_words,101\n",
      "reporter:status:procesando risk\n",
      "reporter:counter:ApplicationCounter,num_words,102\n",
      "reporter:status:procesando analysis,\n",
      "reporter:counter:ApplicationCounter,num_words,103\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,104\n",
      "reporter:status:procesando fraud\n",
      "reporter:counter:ApplicationCounter,num_words,105\n",
      "reporter:status:procesando analytics.\n",
      "reporter:counter:ApplicationCounter,num_words,106\n",
      "reporter:status:procesando Since\n",
      "reporter:counter:ApplicationCounter,num_words,107\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,108\n",
      "reporter:status:procesando can\n",
      "reporter:counter:ApplicationCounter,num_words,109\n",
      "reporter:status:procesando require\n",
      "reporter:counter:ApplicationCounter,num_words,110\n",
      "reporter:status:procesando extensive\n",
      "reporter:counter:ApplicationCounter,num_words,111\n",
      "reporter:status:procesando computation\n",
      "reporter:counter:ApplicationCounter,num_words,112\n",
      "reporter:status:procesando (see\n",
      "reporter:counter:ApplicationCounter,num_words,113\n",
      "reporter:status:procesando big\n",
      "reporter:counter:ApplicationCounter,num_words,114\n",
      "reporter:status:procesando data),\n",
      "reporter:counter:ApplicationCounter,num_words,115\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,116\n",
      "reporter:status:procesando algorithms\n",
      "reporter:counter:ApplicationCounter,num_words,117\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,118\n",
      "reporter:status:procesando software\n",
      "reporter:counter:ApplicationCounter,num_words,119\n",
      "reporter:status:procesando used\n",
      "reporter:counter:ApplicationCounter,num_words,120\n",
      "reporter:status:procesando for\n",
      "reporter:counter:ApplicationCounter,num_words,121\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,122\n",
      "reporter:status:procesando harness\n",
      "reporter:counter:ApplicationCounter,num_words,123\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,124\n",
      "reporter:status:procesando most\n",
      "reporter:counter:ApplicationCounter,num_words,125\n",
      "reporter:status:procesando current\n",
      "reporter:counter:ApplicationCounter,num_words,126\n",
      "reporter:status:procesando methods\n",
      "reporter:counter:ApplicationCounter,num_words,127\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,128\n",
      "reporter:status:procesando computer\n",
      "reporter:counter:ApplicationCounter,num_words,129\n",
      "reporter:status:procesando science,\n",
      "reporter:counter:ApplicationCounter,num_words,130\n",
      "reporter:status:procesando statistics,\n",
      "reporter:counter:ApplicationCounter,num_words,131\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,132\n",
      "reporter:status:procesando mathematics.The\n",
      "reporter:counter:ApplicationCounter,num_words,133\n",
      "reporter:status:procesando field\n",
      "reporter:counter:ApplicationCounter,num_words,134\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,135\n",
      "reporter:status:procesando data\n",
      "reporter:counter:ApplicationCounter,num_words,136\n",
      "reporter:status:procesando analysis.\n",
      "reporter:counter:ApplicationCounter,num_words,137\n",
      "reporter:status:procesando Analytics\n",
      "reporter:counter:ApplicationCounter,num_words,138\n",
      "reporter:status:procesando often\n",
      "reporter:counter:ApplicationCounter,num_words,139\n",
      "reporter:status:procesando involves\n",
      "reporter:counter:ApplicationCounter,num_words,140\n",
      "reporter:status:procesando studying\n",
      "reporter:counter:ApplicationCounter,num_words,141\n",
      "reporter:status:procesando past\n",
      "reporter:counter:ApplicationCounter,num_words,142\n",
      "reporter:status:procesando historical\n",
      "reporter:counter:ApplicationCounter,num_words,143\n",
      "reporter:status:procesando data\n",
      "reporter:counter:ApplicationCounter,num_words,144\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,145\n",
      "reporter:status:procesando research\n",
      "reporter:counter:ApplicationCounter,num_words,146\n",
      "reporter:status:procesando potential\n",
      "reporter:counter:ApplicationCounter,num_words,147\n",
      "reporter:status:procesando trends,\n",
      "reporter:counter:ApplicationCounter,num_words,148\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,149\n",
      "reporter:status:procesando analyze\n",
      "reporter:counter:ApplicationCounter,num_words,150\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,151\n",
      "reporter:status:procesando effects\n",
      "reporter:counter:ApplicationCounter,num_words,152\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,153\n",
      "reporter:status:procesando certain\n",
      "reporter:counter:ApplicationCounter,num_words,154\n",
      "reporter:status:procesando decisions\n",
      "reporter:counter:ApplicationCounter,num_words,155\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,156\n",
      "reporter:status:procesando events,\n",
      "reporter:counter:ApplicationCounter,num_words,157\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,158\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,159\n",
      "reporter:status:procesando evaluate\n",
      "reporter:counter:ApplicationCounter,num_words,160\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,161\n",
      "reporter:status:procesando performance\n",
      "reporter:counter:ApplicationCounter,num_words,162\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,163\n",
      "reporter:status:procesando a\n",
      "reporter:counter:ApplicationCounter,num_words,164\n",
      "reporter:status:procesando given\n",
      "reporter:counter:ApplicationCounter,num_words,165\n",
      "reporter:status:procesando tool\n",
      "reporter:counter:ApplicationCounter,num_words,166\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,167\n",
      "reporter:status:procesando scenario.\n",
      "reporter:counter:ApplicationCounter,num_words,168\n",
      "reporter:status:procesando The\n",
      "reporter:counter:ApplicationCounter,num_words,169\n",
      "reporter:status:procesando goal\n",
      "reporter:counter:ApplicationCounter,num_words,170\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,171\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,172\n",
      "reporter:status:procesando is\n",
      "reporter:counter:ApplicationCounter,num_words,173\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,174\n",
      "reporter:status:procesando improve\n",
      "reporter:counter:ApplicationCounter,num_words,175\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,176\n",
      "reporter:status:procesando business\n",
      "reporter:counter:ApplicationCounter,num_words,177\n",
      "reporter:status:procesando by\n",
      "reporter:counter:ApplicationCounter,num_words,178\n",
      "reporter:status:procesando gaining\n",
      "reporter:counter:ApplicationCounter,num_words,179\n",
      "reporter:status:procesando knowledge\n",
      "reporter:counter:ApplicationCounter,num_words,180\n",
      "reporter:status:procesando which\n",
      "reporter:counter:ApplicationCounter,num_words,181\n",
      "reporter:status:procesando can\n",
      "reporter:counter:ApplicationCounter,num_words,182\n",
      "reporter:status:procesando be\n",
      "reporter:counter:ApplicationCounter,num_words,183\n",
      "reporter:status:procesando used\n",
      "reporter:counter:ApplicationCounter,num_words,184\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,185\n",
      "reporter:status:procesando make\n",
      "reporter:counter:ApplicationCounter,num_words,186\n",
      "reporter:status:procesando improvements\n",
      "reporter:counter:ApplicationCounter,num_words,187\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,188\n",
      "reporter:status:procesando changes.Data\n",
      "reporter:counter:ApplicationCounter,num_words,189\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,190\n",
      "reporter:status:procesando (DA)\n",
      "reporter:counter:ApplicationCounter,num_words,191\n",
      "reporter:status:procesando is\n",
      "reporter:counter:ApplicationCounter,num_words,192\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,193\n",
      "reporter:status:procesando process\n",
      "reporter:counter:ApplicationCounter,num_words,194\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,195\n",
      "reporter:status:procesando examining\n",
      "reporter:counter:ApplicationCounter,num_words,196\n",
      "reporter:status:procesando data\n",
      "reporter:counter:ApplicationCounter,num_words,197\n",
      "reporter:status:procesando sets\n",
      "reporter:counter:ApplicationCounter,num_words,198\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,199\n",
      "reporter:status:procesando order\n",
      "reporter:counter:ApplicationCounter,num_words,200\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,201\n",
      "reporter:status:procesando draw\n",
      "reporter:counter:ApplicationCounter,num_words,202\n",
      "reporter:status:procesando conclusions\n",
      "reporter:counter:ApplicationCounter,num_words,203\n",
      "reporter:status:procesando about\n",
      "reporter:counter:ApplicationCounter,num_words,204\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,205\n",
      "reporter:status:procesando information\n",
      "reporter:counter:ApplicationCounter,num_words,206\n",
      "reporter:status:procesando they\n",
      "reporter:counter:ApplicationCounter,num_words,207\n",
      "reporter:status:procesando contain,\n",
      "reporter:counter:ApplicationCounter,num_words,208\n",
      "reporter:status:procesando increasingly\n",
      "reporter:counter:ApplicationCounter,num_words,209\n",
      "reporter:status:procesando with\n",
      "reporter:counter:ApplicationCounter,num_words,210\n",
      "reporter:status:procesando the\n",
      "reporter:counter:ApplicationCounter,num_words,211\n",
      "reporter:status:procesando aid\n",
      "reporter:counter:ApplicationCounter,num_words,212\n",
      "reporter:status:procesando of\n",
      "reporter:counter:ApplicationCounter,num_words,213\n",
      "reporter:status:procesando specialized\n",
      "reporter:counter:ApplicationCounter,num_words,214\n",
      "reporter:status:procesando systems\n",
      "reporter:counter:ApplicationCounter,num_words,215\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,216\n",
      "reporter:status:procesando software.\n",
      "reporter:counter:ApplicationCounter,num_words,217\n",
      "reporter:status:procesando Data\n",
      "reporter:counter:ApplicationCounter,num_words,218\n",
      "reporter:status:procesando analytics\n",
      "reporter:counter:ApplicationCounter,num_words,219\n",
      "reporter:status:procesando technologies\n",
      "reporter:counter:ApplicationCounter,num_words,220\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,221\n",
      "reporter:status:procesando techniques\n",
      "reporter:counter:ApplicationCounter,num_words,222\n",
      "reporter:status:procesando are\n",
      "reporter:counter:ApplicationCounter,num_words,223\n",
      "reporter:status:procesando widely\n",
      "reporter:counter:ApplicationCounter,num_words,224\n",
      "reporter:status:procesando used\n",
      "reporter:counter:ApplicationCounter,num_words,225\n",
      "reporter:status:procesando in\n",
      "reporter:counter:ApplicationCounter,num_words,226\n",
      "reporter:status:procesando commercial\n",
      "reporter:counter:ApplicationCounter,num_words,227\n",
      "reporter:status:procesando industries\n",
      "reporter:counter:ApplicationCounter,num_words,228\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,229\n",
      "reporter:status:procesando enable\n",
      "reporter:counter:ApplicationCounter,num_words,230\n",
      "reporter:status:procesando organizations\n",
      "reporter:counter:ApplicationCounter,num_words,231\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,232\n",
      "reporter:status:procesando make\n",
      "reporter:counter:ApplicationCounter,num_words,233\n",
      "reporter:status:procesando more-informed\n",
      "reporter:counter:ApplicationCounter,num_words,234\n",
      "reporter:status:procesando business\n",
      "reporter:counter:ApplicationCounter,num_words,235\n",
      "reporter:status:procesando decisions\n",
      "reporter:counter:ApplicationCounter,num_words,236\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,237\n",
      "reporter:status:procesando by\n",
      "reporter:counter:ApplicationCounter,num_words,238\n",
      "reporter:status:procesando scientists\n",
      "reporter:counter:ApplicationCounter,num_words,239\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,240\n",
      "reporter:status:procesando researchers\n",
      "reporter:counter:ApplicationCounter,num_words,241\n",
      "reporter:status:procesando to\n",
      "reporter:counter:ApplicationCounter,num_words,242\n",
      "reporter:status:procesando verify\n",
      "reporter:counter:ApplicationCounter,num_words,243\n",
      "reporter:status:procesando or\n",
      "reporter:counter:ApplicationCounter,num_words,244\n",
      "reporter:status:procesando disprove\n",
      "reporter:counter:ApplicationCounter,num_words,245\n",
      "reporter:status:procesando scientific\n",
      "reporter:counter:ApplicationCounter,num_words,246\n",
      "reporter:status:procesando models,\n",
      "reporter:counter:ApplicationCounter,num_words,247\n",
      "reporter:status:procesando theories\n",
      "reporter:counter:ApplicationCounter,num_words,248\n",
      "reporter:status:procesando and\n",
      "reporter:counter:ApplicationCounter,num_words,249\n",
      "reporter:status:procesando hypotheses.\n",
      "reporter:counter:ApplicationCounter,num_words,250\n",
      "(DA)\t1\n",
      "(see\t1\n",
      "Analytics\t2\n",
      "Analytics,\t1\n",
      "Big\t1\n",
      "Data\t2\n",
      "Especially\t1\n",
      "Organizations\t1\n",
      "Since\t1\n",
      "Specifically,\t1\n"
     ]
    }
   ],
   "source": [
    "## La función sort hace que todos los elementos con \n",
    "## la misma clave queden en lineas consecutivas.\n",
    "## Hace el papel del módulo Shuffle & Sort\n",
    "!cat ./input/text*.txt | ./mapper.py | sort | ./reducer.py | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6\n",
    "\n",
    "Una vez se tienen las versiones anteriores funcionando, se puede proceder a ejecutar la tarea directamente en hadoop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 21:04:49,499 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "## crea el directorio para los archivos de entrada\n",
    "!$HADOOP_HOME/bin/hadoop fs -mkdir input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 21:04:52,478 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "## Copia el contenido de la carpeta input a la carpeta input en el HDFS\n",
    "!$HADOOP_HOME/bin/hadoop fs -put  input/* input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 21:04:54,633 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "-rw-r--r--   1 jdvelasq supergroup       1092 2018-09-02 21:04 input/text0.txt\n",
      "-rw-r--r--   1 jdvelasq supergroup        351 2018-09-02 21:04 input/text1.txt\n",
      "-rw-r--r--   1 jdvelasq supergroup        439 2018-09-02 21:04 input/text2.txt\n"
     ]
    }
   ],
   "source": [
    "## verifica el contenido del directorio\n",
    "!$HADOOP_HOME/bin/hadoop fs -ls input/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 21:04:59,599 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2018-09-02 21:05:00,373 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties\n",
      "2018-09-02 21:05:00,426 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2018-09-02 21:05:00,426 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2018-09-02 21:05:00,438 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2018-09-02 21:05:00,815 INFO mapred.FileInputFormat: Total input files to process : 3\n",
      "2018-09-02 21:05:00,865 INFO mapreduce.JobSubmitter: number of splits:3\n",
      "2018-09-02 21:05:00,986 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local527480485_0001\n",
      "2018-09-02 21:05:00,987 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2018-09-02 21:05:01,083 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2018-09-02 21:05:01,084 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2018-09-02 21:05:01,084 INFO mapreduce.Job: Running job: job_local527480485_0001\n",
      "2018-09-02 21:05:01,086 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "2018-09-02 21:05:01,089 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2018-09-02 21:05:01,089 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2018-09-02 21:05:01,116 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2018-09-02 21:05:01,118 INFO mapred.LocalJobRunner: Starting task: attempt_local527480485_0001_m_000000_0\n",
      "2018-09-02 21:05:01,138 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2018-09-02 21:05:01,139 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2018-09-02 21:05:01,145 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "2018-09-02 21:05:01,145 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "2018-09-02 21:05:01,150 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/jdvelasq/input/text0.txt:0+1092\n",
      "2018-09-02 21:05:01,165 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2018-09-02 21:05:01,229 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2018-09-02 21:05:01,229 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2018-09-02 21:05:01,229 INFO mapred.MapTask: soft limit at 83886080\n",
      "2018-09-02 21:05:01,229 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2018-09-02 21:05:01,229 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2018-09-02 21:05:01,231 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2018-09-02 21:05:01,239 INFO streaming.PipeMapRed: PipeMapRed exec [/Volumes/JetDrive/GitHub/apache-hadoop-course/./mapper.py]\n",
      "2018-09-02 21:05:01,242 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "2018-09-02 21:05:01,243 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "2018-09-02 21:05:01,243 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "2018-09-02 21:05:01,243 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2018-09-02 21:05:01,243 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "2018-09-02 21:05:01,243 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "2018-09-02 21:05:01,244 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "2018-09-02 21:05:01,244 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2018-09-02 21:05:01,244 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "2018-09-02 21:05:01,244 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "2018-09-02 21:05:01,244 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2018-09-02 21:05:01,245 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "2018-09-02 21:05:01,318 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2018-09-02 21:05:01,318 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2018-09-02 21:05:01,320 INFO streaming.PipeMapRed: Records R/W=14/1\n",
      "2018-09-02 21:05:01,325 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2018-09-02 21:05:01,325 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2018-09-02 21:05:01,327 INFO mapred.LocalJobRunner: \n",
      "2018-09-02 21:05:01,327 INFO mapred.MapTask: Starting flush of map output\n",
      "2018-09-02 21:05:01,327 INFO mapred.MapTask: Spilling map output\n",
      "2018-09-02 21:05:01,327 INFO mapred.MapTask: bufstart = 0; bufend = 1347; bufvoid = 104857600\n",
      "2018-09-02 21:05:01,327 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213868(104855472); length = 529/6553600\n",
      "2018-09-02 21:05:01,349 INFO mapred.MapTask: Finished spill 0\n",
      "2018-09-02 21:05:01,363 INFO mapred.Task: Task:attempt_local527480485_0001_m_000000_0 is done. And is in the process of committing\n",
      "2018-09-02 21:05:01,365 INFO mapred.LocalJobRunner: procesando mathematics.\n",
      "2018-09-02 21:05:01,365 INFO mapred.Task: Task 'attempt_local527480485_0001_m_000000_0' done.\n",
      "2018-09-02 21:05:01,371 INFO mapred.Task: Final Counters for attempt_local527480485_0001_m_000000_0: Counters: 23\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=176716\n",
      "\t\tFILE: Number of bytes written=680688\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1092\n",
      "\t\tHDFS: Number of bytes written=0\n",
      "\t\tHDFS: Number of read operations=5\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=1\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=14\n",
      "\t\tMap output records=133\n",
      "\t\tMap output bytes=1347\n",
      "\t\tMap output materialized bytes=1619\n",
      "\t\tInput split bytes=103\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=133\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=320864256\n",
      "\tApplicationCounter\n",
      "\t\tnum_words=8911\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1092\n",
      "2018-09-02 21:05:01,372 INFO mapred.LocalJobRunner: Finishing task: attempt_local527480485_0001_m_000000_0\n",
      "2018-09-02 21:05:01,372 INFO mapred.LocalJobRunner: Starting task: attempt_local527480485_0001_m_000001_0\n",
      "2018-09-02 21:05:01,373 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2018-09-02 21:05:01,373 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2018-09-02 21:05:01,373 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "2018-09-02 21:05:01,373 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "2018-09-02 21:05:01,374 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/jdvelasq/input/text2.txt:0+439\n",
      "2018-09-02 21:05:01,376 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2018-09-02 21:05:01,436 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2018-09-02 21:05:01,436 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2018-09-02 21:05:01,436 INFO mapred.MapTask: soft limit at 83886080\n",
      "2018-09-02 21:05:01,436 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2018-09-02 21:05:01,436 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2018-09-02 21:05:01,436 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2018-09-02 21:05:01,441 INFO streaming.PipeMapRed: PipeMapRed exec [/Volumes/JetDrive/GitHub/apache-hadoop-course/./mapper.py]\n",
      "2018-09-02 21:05:01,452 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2018-09-02 21:05:01,490 INFO streaming.PipeMapRed: Records R/W=6/1\n",
      "2018-09-02 21:05:01,495 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2018-09-02 21:05:01,495 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2018-09-02 21:05:01,495 INFO mapred.LocalJobRunner: \n",
      "2018-09-02 21:05:01,495 INFO mapred.MapTask: Starting flush of map output\n",
      "2018-09-02 21:05:01,495 INFO mapred.MapTask: Spilling map output\n",
      "2018-09-02 21:05:01,495 INFO mapred.MapTask: bufstart = 0; bufend = 559; bufvoid = 104857600\n",
      "2018-09-02 21:05:01,495 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214152(104856608); length = 245/6553600\n",
      "2018-09-02 21:05:01,506 INFO mapred.MapTask: Finished spill 0\n",
      "2018-09-02 21:05:01,514 INFO mapred.Task: Task:attempt_local527480485_0001_m_000001_0 is done. And is in the process of committing\n",
      "2018-09-02 21:05:01,516 INFO mapred.LocalJobRunner: procesando hypotheses.\n",
      "2018-09-02 21:05:01,516 INFO mapred.Task: Task 'attempt_local527480485_0001_m_000001_0' done.\n",
      "2018-09-02 21:05:01,517 INFO mapred.Task: Final Counters for attempt_local527480485_0001_m_000001_0: Counters: 23\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=177044\n",
      "\t\tFILE: Number of bytes written=681409\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1531\n",
      "\t\tHDFS: Number of bytes written=0\n",
      "\t\tHDFS: Number of read operations=7\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=1\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=6\n",
      "\t\tMap output records=62\n",
      "\t\tMap output bytes=559\n",
      "\t\tMap output materialized bytes=689\n",
      "\t\tInput split bytes=103\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=62\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=426246144\n",
      "\tApplicationCounter\n",
      "\t\tnum_words=1953\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=439\n",
      "2018-09-02 21:05:01,517 INFO mapred.LocalJobRunner: Finishing task: attempt_local527480485_0001_m_000001_0\n",
      "2018-09-02 21:05:01,517 INFO mapred.LocalJobRunner: Starting task: attempt_local527480485_0001_m_000002_0\n",
      "2018-09-02 21:05:01,518 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2018-09-02 21:05:01,518 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2018-09-02 21:05:01,518 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "2018-09-02 21:05:01,518 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "2018-09-02 21:05:01,519 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/jdvelasq/input/text1.txt:0+351\n",
      "2018-09-02 21:05:01,522 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2018-09-02 21:05:01,579 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2018-09-02 21:05:01,580 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2018-09-02 21:05:01,580 INFO mapred.MapTask: soft limit at 83886080\n",
      "2018-09-02 21:05:01,580 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2018-09-02 21:05:01,580 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2018-09-02 21:05:01,580 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2018-09-02 21:05:01,585 INFO streaming.PipeMapRed: PipeMapRed exec [/Volumes/JetDrive/GitHub/apache-hadoop-course/./mapper.py]\n",
      "2018-09-02 21:05:01,597 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2018-09-02 21:05:01,633 INFO streaming.PipeMapRed: Records R/W=4/1\n",
      "2018-09-02 21:05:01,639 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2018-09-02 21:05:01,639 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2018-09-02 21:05:01,639 INFO mapred.LocalJobRunner: \n",
      "2018-09-02 21:05:01,639 INFO mapred.MapTask: Starting flush of map output\n",
      "2018-09-02 21:05:01,639 INFO mapred.MapTask: Spilling map output\n",
      "2018-09-02 21:05:01,639 INFO mapred.MapTask: bufstart = 0; bufend = 463; bufvoid = 104857600\n",
      "2018-09-02 21:05:01,639 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214172(104856688); length = 225/6553600\n",
      "2018-09-02 21:05:01,650 INFO mapred.MapTask: Finished spill 0\n",
      "2018-09-02 21:05:01,657 INFO mapred.Task: Task:attempt_local527480485_0001_m_000002_0 is done. And is in the process of committing\n",
      "2018-09-02 21:05:01,659 INFO mapred.LocalJobRunner: procesando changes.\n",
      "2018-09-02 21:05:01,659 INFO mapred.Task: Task 'attempt_local527480485_0001_m_000002_0' done.\n",
      "2018-09-02 21:05:01,660 INFO mapred.Task: Final Counters for attempt_local527480485_0001_m_000002_0: Counters: 23\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=177372\n",
      "\t\tFILE: Number of bytes written=682024\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1882\n",
      "\t\tHDFS: Number of bytes written=0\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=1\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=4\n",
      "\t\tMap output records=57\n",
      "\t\tMap output bytes=463\n",
      "\t\tMap output materialized bytes=583\n",
      "\t\tInput split bytes=103\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=57\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=531628032\n",
      "\tApplicationCounter\n",
      "\t\tnum_words=1653\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=351\n",
      "2018-09-02 21:05:01,660 INFO mapred.LocalJobRunner: Finishing task: attempt_local527480485_0001_m_000002_0\n",
      "2018-09-02 21:05:01,660 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2018-09-02 21:05:01,662 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2018-09-02 21:05:01,662 INFO mapred.LocalJobRunner: Starting task: attempt_local527480485_0001_r_000000_0\n",
      "2018-09-02 21:05:01,669 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2018-09-02 21:05:01,669 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2018-09-02 21:05:01,669 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\n",
      "2018-09-02 21:05:01,669 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\n",
      "2018-09-02 21:05:01,672 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1aed8f95\n",
      "2018-09-02 21:05:01,673 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2018-09-02 21:05:01,690 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2672505600, maxSingleShuffleLimit=668126400, mergeThreshold=1763853824, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2018-09-02 21:05:01,693 INFO reduce.EventFetcher: attempt_local527480485_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2018-09-02 21:05:01,713 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local527480485_0001_m_000002_0 decomp: 579 len: 583 to MEMORY\n",
      "2018-09-02 21:05:01,716 INFO reduce.InMemoryMapOutput: Read 579 bytes from map-output for attempt_local527480485_0001_m_000002_0\n",
      "2018-09-02 21:05:01,717 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 579, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->579\n",
      "2018-09-02 21:05:01,719 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local527480485_0001_m_000001_0 decomp: 685 len: 689 to MEMORY\n",
      "2018-09-02 21:05:01,720 INFO reduce.InMemoryMapOutput: Read 685 bytes from map-output for attempt_local527480485_0001_m_000001_0\n",
      "2018-09-02 21:05:01,720 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 685, inMemoryMapOutputs.size() -> 2, commitMemory -> 579, usedMemory ->1264\n",
      "2018-09-02 21:05:01,721 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local527480485_0001_m_000000_0 decomp: 1615 len: 1619 to MEMORY\n",
      "2018-09-02 21:05:01,721 INFO reduce.InMemoryMapOutput: Read 1615 bytes from map-output for attempt_local527480485_0001_m_000000_0\n",
      "2018-09-02 21:05:01,721 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 1615, inMemoryMapOutputs.size() -> 3, commitMemory -> 1264, usedMemory ->2879\n",
      "2018-09-02 21:05:01,721 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2018-09-02 21:05:01,722 INFO mapred.LocalJobRunner: 3 / 3 copied.\n",
      "2018-09-02 21:05:01,722 INFO reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2018-09-02 21:05:01,743 INFO mapred.Merger: Merging 3 sorted segments\n",
      "2018-09-02 21:05:01,743 INFO mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 2853 bytes\n",
      "2018-09-02 21:05:01,752 INFO reduce.MergeManagerImpl: Merged 3 segments, 2879 bytes to disk to satisfy reduce memory limit\n",
      "2018-09-02 21:05:01,753 INFO reduce.MergeManagerImpl: Merging 1 files, 2879 bytes from disk\n",
      "2018-09-02 21:05:01,754 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2018-09-02 21:05:01,754 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2018-09-02 21:05:01,755 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 2868 bytes\n",
      "2018-09-02 21:05:01,756 INFO mapred.LocalJobRunner: 3 / 3 copied.\n",
      "2018-09-02 21:05:01,761 INFO streaming.PipeMapRed: PipeMapRed exec [/Volumes/JetDrive/GitHub/apache-hadoop-course/./reducer.py]\n",
      "2018-09-02 21:05:01,763 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2018-09-02 21:05:01,764 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2018-09-02 21:05:01,800 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2018-09-02 21:05:01,800 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2018-09-02 21:05:01,801 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2018-09-02 21:05:01,817 INFO streaming.PipeMapRed: Records R/W=252/1\n",
      "2018-09-02 21:05:01,823 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2018-09-02 21:05:01,823 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2018-09-02 21:05:01,858 INFO mapred.Task: Task:attempt_local527480485_0001_r_000000_0 is done. And is in the process of committing\n",
      "2018-09-02 21:05:01,859 INFO mapred.LocalJobRunner: 3 / 3 copied.\n",
      "2018-09-02 21:05:01,859 INFO mapred.Task: Task attempt_local527480485_0001_r_000000_0 is allowed to commit now\n",
      "2018-09-02 21:05:01,867 INFO output.FileOutputCommitter: Saved output of task 'attempt_local527480485_0001_r_000000_0' to hdfs://localhost:9000/user/jdvelasq/output\n",
      "2018-09-02 21:05:01,867 INFO mapred.LocalJobRunner: Records R/W=252/1 > reduce\n",
      "2018-09-02 21:05:01,868 INFO mapred.Task: Task 'attempt_local527480485_0001_r_000000_0' done.\n",
      "2018-09-02 21:05:01,868 INFO mapred.Task: Final Counters for attempt_local527480485_0001_r_000000_0: Counters: 29\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=183238\n",
      "\t\tFILE: Number of bytes written=684903\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1882\n",
      "\t\tHDFS: Number of bytes written=1649\n",
      "\t\tHDFS: Number of read operations=14\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=3\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=159\n",
      "\t\tReduce shuffle bytes=2891\n",
      "\t\tReduce input records=252\n",
      "\t\tReduce output records=159\n",
      "\t\tSpilled Records=252\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=9\n",
      "\t\tTotal committed heap usage (bytes)=561512448\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1649\n",
      "2018-09-02 21:05:01,868 INFO mapred.LocalJobRunner: Finishing task: attempt_local527480485_0001_r_000000_0\n",
      "2018-09-02 21:05:01,868 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2018-09-02 21:05:02,094 INFO mapreduce.Job: Job job_local527480485_0001 running in uber mode : false\n",
      "2018-09-02 21:05:02,095 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2018-09-02 21:05:02,096 INFO mapreduce.Job: Job job_local527480485_0001 completed successfully\n",
      "2018-09-02 21:05:02,103 INFO mapreduce.Job: Counters: 36\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=714370\n",
      "\t\tFILE: Number of bytes written=2729024\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=6387\n",
      "\t\tHDFS: Number of bytes written=1649\n",
      "\t\tHDFS: Number of read operations=35\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=6\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=24\n",
      "\t\tMap output records=252\n",
      "\t\tMap output bytes=2369\n",
      "\t\tMap output materialized bytes=2891\n",
      "\t\tInput split bytes=309\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=159\n",
      "\t\tReduce shuffle bytes=2891\n",
      "\t\tReduce input records=252\n",
      "\t\tReduce output records=159\n",
      "\t\tSpilled Records=504\n",
      "\t\tShuffled Maps =3\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=3\n",
      "\t\tGC time elapsed (ms)=9\n",
      "\t\tTotal committed heap usage (bytes)=1840250880\n",
      "\tApplicationCounter\n",
      "\t\tnum_words=12517\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1882\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=1649\n",
      "2018-09-02 21:05:02,103 INFO streaming.StreamJob: Output directory: output\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Se ejecuta en Hadoop.\n",
    "##   -input: archivo de entrada\n",
    "##   -output: directorio de salida\n",
    "##   -maper: programa que ejecuta el map\n",
    "##   -reducer: programa que ejecuta la reducción\n",
    "##\n",
    "!$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar -input input -output output  -mapper mapper.py -reducer reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 21:05:08,193 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 2 items\n",
      "-rw-r--r--   1 jdvelasq supergroup          0 2018-09-02 21:05 output/_SUCCESS\n",
      "-rw-r--r--   1 jdvelasq supergroup       1649 2018-09-02 21:05 output/part-00000\n"
     ]
    }
   ],
   "source": [
    "## contenido del directorio con los \n",
    "## resultados de la corrida\n",
    "!$HADOOP_HOME/bin/hadoop fs -ls output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 21:05:11,926 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "(DA)\t1\n",
      "(see\t1\n",
      "Analytics\t2\n",
      "Analytics,\t1\n",
      "Big\t1\n",
      "Data\t3\n",
      "Especially\t1\n",
      "Organizations\t1\n",
      "Since\t1\n",
      "Specifically,\t1\n"
     ]
    }
   ],
   "source": [
    "## se visualiza el archivo con los\n",
    "## resultados de la corrida\n",
    "!$HADOOP_HOME/bin/hadoop fs -cat output/part-00000 | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 21:05:17,559 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Deleted input/text0.txt\n",
      "Deleted input/text1.txt\n",
      "Deleted input/text2.txt\n",
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-00000\n",
      "2018-09-02 21:05:19,293 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "!rm reducer.py mapper.py\n",
    "!rm -rf input\n",
    "!$HADOOP_HOME/bin/hadoop fs -rm input/* output/*\n",
    "!$HADOOP_HOME/bin/hadoop fs -rmdir input output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop/MapReduce -- WordCount en Python (Implementación eficiente)\n",
    "===\n",
    "\n",
    "**Juan David Velásquez Henao**  \n",
    "jdvelasq@unal.edu.co   \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia\n",
    "\n",
    "---\n",
    "\n",
    "Haga click [aquí](https://github.com/jdvelasq/big-data-analytics/tree/master/) para acceder al repositorio online.\n",
    "\n",
    "Haga click [aquí](http://nbviewer.jupyter.org/github/jdvelasq/big-data-analytics/tree/master/) para explorar el repositorio usando `nbviewer`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
